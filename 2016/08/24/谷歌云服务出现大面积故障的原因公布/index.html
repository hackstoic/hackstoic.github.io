<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="viewpoint from a programmer, think like a life hacker."><title>谷歌云服务出现大面积故障的原因公布 | Hackstoic's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">谷歌云服务出现大面积故障的原因公布</h1><a id="logo" href="/.">Hackstoic's Blog</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">谷歌云服务出现大面积故障的原因公布</h1><div class="post-meta">Aug 24, 2016<script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="post-content"><blockquote>
<p>原文链接： <a href="https://status.cloud.google.com/incident/appengine/16008#5673385510043648" target="_blank" rel="external">https://status.cloud.google.com/incident/appengine/16008#5673385510043648</a><br>原文镜像：<a href="https://hackstoic.github.io/2016/08/25/Google_App_Engine_Incident_16008/" target="_blank" rel="external">https://hackstoic.github.io/2016/08/25/Google_App_Engine_Incident_16008/</a><br>本文仅供学习参考。 水平有限，如有翻译谬误，还望指出。欢迎转载，转载请附上本文地址和作者hackstoic。 </p>
</blockquote>
<p>App Engine 服务中断故障</p>
<p>故障发生在 2016-08-11 13:13， 并于 2016-08-11 15:00 恢复正常(上述时间均为 US/Pacific时间).</p>
<p>Aug 23, 2016    09:54    </p>
<h3 id="SUMMARY-概述"><a href="#SUMMARY-概述" class="headerlink" title="SUMMARY(概述)"></a>SUMMARY(概述)</h3><p>On Thursday 11 August 2016, 21% of Google App Engine applications hosted in the US-CENTRAL region experienced error rates in excess of 10% and elevated latency between 13:13 and 15:00 PDT. An additional 16% of applications hosted on the same GAE instance observed lower rates of errors and latency during the same period.<br>2016年8月11号星期四， 托管在Google App Engine（译者注： google的PaaS云服务)的US-CENTRAL区域 的21%的应用在太平洋时间的白天13:13 － 15:00之间经历了超过10%的出错率和不断升高的访问延时。 </p>
<p>We apologize for this incident. We know that you choose to run your applications on Google App Engine to obtain flexible, reliable, high-performance service, and in this incident we have not delivered the level of reliability for which we strive. Our engineers have been working hard to analyze what went wrong and ensure incidents of this type will not recur.</p>
<p>我们为这次事故深感歉意。 我们深知您选择在我们的云平台运行应用是为了能够获得灵活可靠，高质量的服务。 在这次事故中， 我们并没有提供好我们所追求的高可靠服务。我们的工程师日夜兼程的分析事故的原因，以保证此类事故不会再发生。  </p>
<h3 id="DETAILED-DESCRIPTION-OF-IMPACT-细节和影响"><a href="#DETAILED-DESCRIPTION-OF-IMPACT-细节和影响" class="headerlink" title="DETAILED DESCRIPTION OF IMPACT(细节和影响)"></a>DETAILED DESCRIPTION OF IMPACT(细节和影响)</h3><p>On Thursday 11 August 2016 from 13:13 to 15:00 PDT, 18% of applications hosted in the US-CENTRAL region experienced error rates between 10% and 50%, and 3% of applications experienced error rates in excess of 50%. Additionally, 14% experienced error rates between 1% and 10%, and 2% experienced error rate below 1% but above baseline levels. In addition, the 37% of applications which experienced elevated error rates also observed a median latency increase of just under 0.8 seconds per request.</p>
<p>太平洋时间2016年8月11日 13:13 － 15:00之间， 托管在在US-CENTRAL 区域的应用，有18%的应用出错概率在 10% 到 50% 之间， 其中 3% 的应用出错概率超过 50%，14% 的应用出错概率在 1% 到 10% 之间，有 2% 的应用出错率在 1% 以下但依然高于正常水平。这37%的应用遭受了不断攀升的出错率， 且其每次请求的平均延时在0.8s以下。 剩余 63% 的应用访问正常，没有受到影响。 </p>
<p>The remaining 63% of applications hosted on the same GAE instance, and applications hosted on other GAE instances, did not observe elevated error rates or increased latency.</p>
<p>Both App Engine Standard and Flexible Environment applications in US-CENTRAL were affected by this incident. In addition, some Flexible Environment applications were unable to deploy new versions during this incident.<br>App Engine applications in US-EAST1 and EUROPE-WEST were not impacted by this incident.</p>
<p>托管在US-CENTRAL区域的App Engine的标准环境和仿真环境的应用均受到此次事故的影响。 一些仿真环境的应用无法在事故发生期间部署新的版本。 所有在US-EAST1 和 EUROPE-WEST的应用没有受到影响。 </p>
<p>App Engine applications in US-EAST1 and EUROPE-WEST were not impacted by this incident.</p>
<h3 id="ROOT-CAUSE-事故原因分析"><a href="#ROOT-CAUSE-事故原因分析" class="headerlink" title="ROOT CAUSE(事故原因分析)"></a>ROOT CAUSE(事故原因分析)</h3><p>The incident was triggered by a periodic maintenance procedure in which Google engineers move App Engine applications between datacenters in US-CENTRAL in order to balance traffic more evenly. </p>
<p>这次事故是由一次例行的维护工作导致的。 谷歌的工程师为使负载流量更加均衡， 在US-CENTRAL区域内做app迁移。 </p>
<p>As part of this procedure, we first move a proportion of apps to a new datacenter in which capacity has already been provisioned. We then gracefully drain traffic from an equivalent proportion of servers in the downsized datacenter in order to reclaim resources. The applications running on the drained servers are automatically rescheduled onto different servers.  </p>
<p>我们配置了新的数据中心， 我们先挪走了一定比例的app到新的数据中心，然后逐渐把相当比例的服务器的流量从旧的数据中心导向新的数据中心，以重新分配资源。 运行在被引走流量的服务器上的应用会自动在不同的服务器上重新计划启动。 </p>
<p>During this procedure, a software update on the traffic routers was also in progress, and this update triggered a rolling restart of the traffic routers. This temporarily diminished the available router capacity.<br>不巧的是， 在这个迁移过程中， 在负载均衡路由器上同时运行着软件升级。 软件升级触发了负载均衡路由器的不断重启。 这减少路由器上可用的负载容量。 </p>
<p>The server drain resulted in rescheduling of multiple instances of manually-scaled applications. App Engine creates new instances of manually-scaled applications by sending a startup request via the traffic routers to the server hosting the new instance.<br>服务器流量引流导致不少手动扩容的应用进行流量重定向。 App Engine 通过负载均衡路由器向托管新应用的服务器发送启动的请求，为这些手动扩容的应用创建新的实例。 </p>
<p>Some manually-scaled instances started up slowly, resulting in the App Engine system retrying the start requests multiple times which caused a spike in CPU load on the traffic routers. The overloaded traffic routers dropped some incoming requests.<br>一些手动扩容的实例启动的比较慢， 导致了App Engine系统不断向这些应用发送重启的请求， 负载均衡路由器出现了cpu负载峰值， 负载均衡路由器由于过载，从而丢掉了一些入流量。 </p>
<p>Although there was sufficient capacity in the system to handle the load, the traffic routers did not immediately recover due to retry behavior which amplified the volume of requests.<br>尽管处理这些负载的系统的容量是足够的， 但是由于不断的重试请求，进一步加重了路由器负载， 从而使负载均衡路由器不能立即恢复过来。 </p>
<h3 id="REMEDIATION-AND-PREVENTION-补救和避免措施"><a href="#REMEDIATION-AND-PREVENTION-补救和避免措施" class="headerlink" title="REMEDIATION AND PREVENTION(补救和避免措施)"></a>REMEDIATION AND PREVENTION(补救和避免措施)</h3><p>Google engineers were monitoring the system during the datacenter changes and immediately noticed the problem. Although we rolled back the change that drained the servers within 11 minutes, this did not sufficiently mitigate the issue because retry requests had generated enough additional traffic to keep the system’s total load at a substantially higher-than-normal level.<br>谷歌的工程师通过监控数据中心的变化， 立即发现了这次问题。 尽管我们紧急在11分钟内紧急做了回滚， 但是并没有有效的减轻这次事故， 因为不断的重试请求已经让系统的总体负载一直处于高于平常的水平。 </p>
<p>As designed, App Engine automatically redirected requests to other datacenters away from the overload - which reduced the error rate. Additionally, our engineers manually redirected all traffic at 13:56 to other datacenters which further mitigated the issue.<br>根据之前的设计， App Engine自动从过载的数据中心重定向请求到其它数据中心，以减少出错概率。 此外， 我们的工程师在13:56时， 手动重定向了所有的流量到其它数据中心， 重新减轻了这次事故的影响。 </p>
<p>Finally, we then identified a configuration error that caused an imbalance of traffic in the new datacenters. Fixing this at 15:00 finally fully resolved the incident.<br>最后我们定位了一个配置错误。 这个配置错误导致了在新数据中心间的流量不均问题。 我们在15:00时修复了这个错误， 最后完全解决了这个事故。 </p>
<p>In order to prevent a recurrence of this type of incident, we have added more traffic routing capacity in order to create more capacity buffer when draining servers in this region.  </p>
<p>为了避免此类事故的再次发生， 我们增加了更多流量路由的容量， 来保证在该区域进行服务器引流的时候有更多的缓冲空间。 </p>
<p>We will also change how applications are rescheduled so that the traffic routers are not called and also modify that the system’s retry behavior so that it cannot trigger this type of failure. </p>
<p>我们也改变了应用漂移的策略，因此流量路由器不会被调用，同时修改了系统的重试策略， 从而使它不会再触发这类问题。 </p>
<p>We know that you rely on our infrastructure to run your important workloads and that this incident does not meet our bar for reliability. For that we apologize. Your trust is important to us and we will continue to all we can to earn and keep that trust.<br>我们深知你们对运行你们的重要负载的基础设施是很依赖的。 这次事故并没有达到我们对可靠性的要求。 对此， 我们深表歉意。 您的信任对于我们是十分重要的， 我们将继续竭尽全力来承载您的信任。 </p>
<p> <strong>Aug 11, 2016    15:45</strong></p>
<blockquote>
<p>The issue with App Engine APIs is now resolved for most of the affected projects as of 14:12 US/Pacific. We will follow up directly with the few remaining affected applications. We will also conduct a thorough internal investigation of this issue and make appropriate improvements to our systems to prevent or minimize any future recurrence. Finally, we will publish a more detailed analysis of this incident once we have completed an internal investigation.<br>大部分受影响的项目的App Engine API的问题在14:12的时候被解决。 我们继续跟进剩余的少量受影响的应用。 我们将彻底的调用这次时间， 并制定一个合理的改善措施来完善我们的系统， 避免或者最小限度的减少此类事故的再次发生。 最后， 一旦我们完成了内部调查，我们将会发布一份详细的事故分析报告。 </p>
</blockquote>
<p> <strong>Aug 11, 2016    15:15</strong></p>
<blockquote>
<p>We are still investigating the issue with App Engine apis being unavailable.<br>我们仍旧接着调查 App Engine  api不可用的问题。<br>Current data indicates that some projects are affected by this issue. We will provide another status update by 15:45 US/Pacific with current details.<br>当前数据表明一些项目受到此次事件的影响。 我们在 15:45提供了一份状态更新报告。 </p>
</blockquote>
<p><strong>Aug 11, 2016 14:44</strong></p>
<blockquote>
<p>The issue with App Engine apis being unavailable should have been resolved for the majority of projects and we expect a full resolution in the near future.<br>大部分项目的App Engine api 不可用的问题本该被解决， 我们希望在不久的将来有一个完整的决议。<br>We will provide another status update by 15:15 US/Pacific with current details.<br>我们在15：15提供了另外一份当前细节的状态更新报告。 </p>
</blockquote>
<p><strong>Aug 11, 2016    14:16</strong></p>
<blockquote>
<p>We are experiencing an issue with App Engine apis being unavailable beginning at Thursday, 2016-08-11 13:45 US/Pacific.<br>Current data indicates that Applications in us-central are affected by this issue.<br>我们发现App Engine 的api在13:45分就开始不可用。 当前的数据表明us-central 的应用受到此次事件的影响。 </p>
</blockquote>
<p><strong>Aug 11, 2016     14:01</strong></p>
<blockquote>
<p>We are investigating reports of an issue with App Engine. We will provide more information by 02:15 US/Pacific.<br>我们调查了 App Engine的这次事故， 并在太平洋时间02:15提供了更多细节的信息。 </p>
</blockquote>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://yoursite.com/2016/08/24/谷歌云服务出现大面积故障的原因公布/" data-id="ciule2hru000rcjgd4j7mlwkx" class="article-share-link">分享到</a><div class="tags"></div><div class="post-nav"><a href="/2016/08/25/Google_App_Engine_Incident_16008/" class="pre">Google_App_Engine_Incident_16008</a><a href="/2016/08/22/微信命令行/" class="next">微信命令行</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/10/09/读“技术的执念”有感/">读“技术的执念”有感</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/29/内网翻墙集群搭建/">内网翻墙集群搭建</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/16/上海Qcon 2016 值得关注的技术(精简版)/">2016 上海Qcon 值得关注的技术</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/16/上海 Qcon 2016  值得关注的技术(完整版)/">2016 上海 Qcon 值得关注的技术</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/10/内网穿透/">内网穿透</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/09/06/kubernetes初探/">kubernetes初探</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/28/0gopher meetup 深圳站2016-08-28/">gopher meetup 深圳站2016-08-28</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/27/开源web堡垒机GateOne初探（2）/">开源web堡垒机GateOne初探（2）</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/27/开源web堡垒机GateOne初探（1）/">开源web堡垒机GateOne初探（1）</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/27/搭建NGINX+UWSGI+DJANGO+MYSQL环境/">搭建NGINX+UWSGI+DJANGO+MYSQL环境</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://coolshell.cn/" title="酷壳" target="_blank">酷壳</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Hackstoic's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>